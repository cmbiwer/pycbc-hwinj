#! /usr/bin/env pythonn

import argparse
import logging
import numpy
import os
import urlparse
import shutil
import ligo.gracedb.rest as gracedb_rest
import Pegasus.DAX3 as dax
from glue import segments
from pycbc_hwinj.frame import get_frame_files
from pycbc import workflow
from pycbc.workflow.core import make_external_call, SegFile

##### setup

# read command line
parser = argparse.ArgumentParser(usage="pycbc_make_cal_workflow [--options]",
                                 description="Workflow generator for adjusting calibration model.")
parser.add_argument("--name", type=str, required=True,
                    help="Descriptive name of the analysis.")
workflow.add_workflow_command_line_group(parser)
opts = parser.parse_args()

# setup log
logging.basicConfig(format="%(asctime)s:%(levelname)s : %(message)s",
                    level=logging.INFO,datefmt="%I:%M:%S")

# directory names
run_dir = os.path.join(os.getcwd(), opts.name)
datafind_dir = os.path.join(run_dir, "datafind")
check_segdb_dir = os.path.join(run_dir, "check_segdb")
check_exc_dir = os.path.join(run_dir, "check_exc")
check_bitmask_dir = os.path.join(run_dir, "check_bitmask")
check_gracedb_dir = os.path.join(run_dir, "check_gracedb")
check_schedule_dir = os.path.join(run_dir, "check_schedule")

# change into run directory and make directories that are needed
if not os.path.exists(run_dir):
    os.makedirs(run_dir)
os.chdir(run_dir)
if not os.path.exists(check_segdb_dir):
    os.makedirs(check_segdb_dir)
    os.makedirs(check_segdb_dir + "/logs")
if not os.path.exists(check_gracedb_dir):
    os.makedirs(check_gracedb_dir)
if not os.path.exists(check_schedule_dir):
    os.makedirs(check_schedule_dir)
os.chdir(run_dir)

# setup workflow
wf = workflow.Workflow(opts, opts.name)

# make a dict to hold frame files for each IFO
frame_files = {}
for ifo in wf.ifos:
    frame_files[ifo] = workflow.FileList([])

# analysis time of each node
stride = 2000

##### check_exc

# create a FileList to hold output files for check_exc executable
check_exc_files = workflow.FileList([])

# loop over subsections of config file for check_exc executable
exe_name = "check_exc"
for subsection in wf.cp.get_subsections(exe_name):

    # get options from config file
    frame_type = wf.cp.get_opt_tags(exe_name, "frame-type", [subsection])
    channel_name = wf.cp.get_opt_tags(exe_name, "channel-name", [subsection])
    ifo = channel_name.split(":")[0]

    # print statement
    logging.info("Creating %s workflow nodes for %s", exe_name, channel_name)

    # setup executable to check for excitations in channel
    check_exc_exe = workflow.Executable(wf.cp, exe_name, ifos=ifo, universe="local",
                                        out_dir=check_exc_dir, tags=[subsection])

    # see if frame files already in workflow and if not then add them
    tmp_files = get_frame_files(wf, frame_files, ifo, frame_type)

    # loop over analysis time for each node
    for start_time in range(wf.analysis_time[0], wf.analysis_time[1], stride):

        # get frame files for this node
        end_time = start_time + stride
        if wf.analysis_time[1] < end_time:
            end_time = wf.analysis_time[1]
        node_seg = segments.segment(start_time, end_time)
        node_frame_files = [tmp_file for tmp_file in tmp_files if tmp_file.segment.intersects(node_seg)]

        # make a node in the workflow to check for excitations
        if len(node_frame_files):
            check_exc_node = check_exc_exe.create_node()
            check_exc_node.add_input_list_opt("--frame-files", node_frame_files)
            check_exc_node.add_opt("--start-time", node_seg[0])
            check_exc_node.add_opt("--end-time", node_seg[1])
            check_exc_file = check_exc_node.new_output_file_opt(node_seg, "txt", "--output-file")
            wf.add_node(check_exc_node)

            # add output file to list of excitation files
            check_exc_files.append(check_exc_file)

##### check_bitmask

# create list for holding output files
check_bitmask_files = workflow.FileList([])

# loop over subsections of config file for check_exc executable
exe_name = "check_bitmask"
for subsection in wf.cp.get_subsections(exe_name):

    # get options from config file
    frame_type = wf.cp.get_opt_tags(exe_name, "frame-type", [subsection])
    channel_name = wf.cp.get_opt_tags(exe_name, "channel-name", [subsection])
    bitmask_name = wf.cp.get_opt_tags(exe_name, "bitmask-name", [subsection])
    ifo = channel_name.split(":")[0]

    # print statement
    logging.info("Creating %s workflow nodes for %s %s", exe_name, channel_name, bitmask_name)

    # setup executable to check for ODC bit transitions in channel
    check_bitmask_exe = workflow.Executable(wf.cp, exe_name, ifos=ifo, universe="local",
                                        out_dir=check_bitmask_dir, tags=[subsection])

    # see if frame files already in workflow and if not then add them
    tmp_files = get_frame_files(wf, frame_files, ifo, frame_type)

    # loop over analysis time for each node
    for start_time in range(wf.analysis_time[0], wf.analysis_time[1], stride):

        # get frame files for this node
        end_time = start_time + stride
        if wf.analysis_time[1] < end_time:
            end_time = wf.analysis_time[1]
        node_seg = segments.segment(start_time, end_time)
        node_frame_files = [tmp_file for tmp_file in tmp_files if tmp_file.segment.intersects(node_seg)]

        # make a node in the workflow to check for excitations
        if len(node_frame_files):
            check_bitmask_node = check_bitmask_exe.create_node()
            check_bitmask_node.add_input_list_opt("--frame-files", node_frame_files)
            check_bitmask_node.add_opt("--start-time", node_seg[0])
            check_bitmask_node.add_opt("--end-time", node_seg[1])
            check_bitmask_file = check_bitmask_node.new_output_file_opt(node_seg, "txt", "--output-file")
            wf.add_node(check_bitmask_node)

            # add output file to list of bitmask files
            check_bitmask_files.append(check_bitmask_file)

##### check_segdb

# create list for holding output files
check_segdb_files = workflow.FileList([])

# loop over subsections of config file for check_exc executable
exe_name = "check_segdb"
for subsection in wf.cp.get_subsections(exe_name):

    # get options from config file
    database_url = wf.cp.get_opt_tags(exe_name, "database-url", [subsection])
    segment_name = wf.cp.get_opt_tags(exe_name, "segment-name", [subsection])
    ifo, segment_flag, version = segment_name.split(":")

    # print statement
    logging.info("Querying %s workflow nodes for %s", exe_name, segment_name)

    # construct output path
    output_path = os.path.join(check_segdb_dir,
        ifo + "-" + segment_flag.replace("-", "_") + "_" + version + "-" + str(wf.analysis_time[0]) + "-" + str(abs(wf.analysis_time)) + ".xml.gz")

    # construct command line for segdb external call
    cmd = [wf.cp.get("executables", exe_name),
            "--query-segments",
            "--segment-url", database_url,
            "--gps-start-time", str(wf.analysis_time[0]),
            "--gps-end-time", str(wf.analysis_time[1]),
            "--include-segments", segment_name,
            "--output-file", output_path]
  
    # make an external call to query segment database
    make_external_call(cmd, out_dir=os.path.join(check_segdb_dir,"logs"),
                            out_basename=ifo.lower() + "-" + segment_flag.lower() + "-" + version)

    # Yes its poor to generate a file and then read it back in
    # new segment database API should fix this
    seg_url  = urlparse.urlunparse(["file", "localhost", output_path,
                                   None, None, None])
    seg_file = workflow.File([ifo], "CHECK_SEGDB", wf.analysis_time,
                            file_url=seg_url, tags=[subsection])
    seg_file.PFN(output_path, site="local")
    check_segdb_files.append(seg_file)

##### check_gracedb

# print statement
logging.info("Querying gracedb rest API for all triggers")

# get gracedb events
client = gracedb_rest.GraceDb()
query = str(wf.analysis_time[0]) + " .. " + str(wf.analysis_time[1])
evnts = client.events(query, orderby="gpstime", columns="graceid,gpstime,pipeline,instruments")

# write gracedb events to file
ifos = "".join(wf.ifos)
path = os.path.join(check_gracedb_dir, ifos + "-" + "GRACEDB" + "-" + str(wf.analysis_time[0]) + "-" + str(abs(wf.analysis_time)) + ".txt")
with open(path, "w") as fp:
    for evnt in evnts:
        line = ",".join(map(str, [evnt["graceid"],
                        evnt["gpstime"], evnt["pipeline"],
                        "".join(evnt["instruments"].split(",")),
        ])) + "\n"
        fp.write(line)
gracedb_file = workflow.File(ifos, "GRACEDB", wf.analysis_time, file_url="file://localhost" + path)
gracedb_file.PFN(path, site="local")

##### check_schedule

# get tinj schedule
schedule_path = wf.cp.get("workflow-schedule", "schedule-path")

# print statement
logging.info("Retrieving schedule file from %s", schedule_path)

# check if schedule exists
if os.path.exists(schedule_path):

    # print statement
    logging.info("Retrieving schedule from %s", schedule_path)

    # copy schedule to run directory
    path = os.path.join(check_schedule_dir, ifos + "-" + "SCHEDULE" + "-" + str(wf.analysis_time[0]) + "-" + str(abs(wf.analysis_time)) + ".txt")
    schedule_file = workflow.File(ifos, "SCHEDULE", wf.analysis_time, file_url="file://localhost" + path)
    schedule_file.PFN(path, site="local")
    shutil.copy(schedule_path, path)

# else print a warning
else:
    logging.warn("Could not find schedule path: %s", schedule_path)

##### cat check_exc

# create an Executable for concatenating excitation files
exe_name = "cat_frame_data"
tag = "EXC"
cat_exc_exe = workflow.Executable(wf.cp, exe_name, ifos=wf.ifo_string, universe="vanilla",
                                        out_dir=check_exc_dir, tags=[tag])

# print statement
logging.info("Creating %s workflow node", exe_name)

# create a node
cat_exc_node = cat_exc_exe.create_node()

# add options
cat_exc_node.add_input_list_opt("--input-files", check_exc_files)
cat_exc_file = cat_exc_node.new_output_file_opt(wf.analysis_time, "txt", "--output-file")

# add node to workflow
wf.add_node(cat_exc_node)

##### cat check_bitmask

# create an Executable for concatenating bitmask files
exe_name = "cat_frame_data"
tag = "BITMASK"
cat_bitmask_exe = workflow.Executable(wf.cp, exe_name, ifos=wf.ifo_string, universe="vanilla",
                                        out_dir=check_bitmask_dir, tags=[tag])

# print statement
logging.info("Creating %s workflow node", exe_name)

# create a node
cat_bitmask_node = cat_bitmask_exe.create_node()

# add options
cat_bitmask_node.add_input_list_opt("--input-files", check_bitmask_files)
cat_bitmask_file = cat_bitmask_node.new_output_file_opt(wf.analysis_time, "txt", "--output-file")

# add node to workflow
wf.add_node(cat_bitmask_node)

##### cat check_segdb

# create an Executable for concatenating excitation files
exe_name = "cat_segdb_data"
cat_segdb_exe = workflow.Executable(wf.cp, exe_name, ifos=wf.ifo_string, universe="vanilla",
                                        out_dir=check_segdb_dir, tags=[])

# print statement
logging.info("Creating %s workflow node", exe_name)

# create a node
cat_segdb_node = cat_segdb_exe.create_node()

# add options
cat_segdb_node.add_input_list_opt("--segment-files", check_segdb_files)
cat_segdb_file = cat_segdb_node.new_output_file_opt(wf.analysis_time, "txt", "--output-file")

# add node to workflow
wf.add_node(cat_segdb_node)

##### make_table

# make sure results directory exists
results_dir = wf.cp.get_opt_tags("workflow-results", "results-dir", [])
if not os.path.exists(results_dir):
    os.makedirs(results_dir)

# create an Executable for creating the html table
exe_name = "make_table"
make_table_exe = workflow.Executable(wf.cp, exe_name, ifos=wf.ifo_string,
                                    universe="local",
                                    out_dir=results_dir, tags=[])

# print statement
logging.info("Creating %s workflow node", exe_name)

# this is not optimal since we assume where the parsed config
# file will be but right now there is not a way around this
config_path = run_dir + "/" + opts.name + "_parsed.ini"
path = results_dir + "/config.ini"
config_file = workflow.File(ifos, "CONFIG", wf.analysis_time, file_url="file://localhost" + path)
config_file.PFN(path, site="local")
shutil.copy(config_path, path)

# create a node
make_table_node = make_table_exe.create_node()

# add options
make_table_node.add_input_opt("--excitation-file", cat_exc_file)
make_table_node.add_input_opt("--bitmask-file", cat_bitmask_file)
make_table_node.add_input_opt("--gracedb-file", gracedb_file)
make_table_node.add_input_opt("--segment-file", cat_segdb_file)
make_table_node.add_input_opt("--schedule-file", schedule_file)
make_table_node.add_input_opt("--config-file", config_file)
make_table_node.add_opt("--start-time", wf.analysis_time[0])
make_table_node.add_opt("--end-time", wf.analysis_time[1])
make_table_html_file = make_table_node.new_output_file_opt(wf.analysis_time, "html", "--output-html-file")
make_table_csv_file = make_table_node.new_output_file_opt(wf.analysis_time, "csv", "--output-csv-file")
make_table_node.add_opt("--output-static-dir", results_dir+"/static/")

# add node to workflow
wf.add_node(make_table_node)

##### finish

# write dax
wf.save()

# done
logging.info("Done")

