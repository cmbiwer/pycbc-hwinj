#! /usr/bin/env pythonn

import argparse
import logging
import numpy
import os
import urlparse
import shutil
import ligo.gracedb.rest as gracedb_rest
import Pegasus.DAX3 as dax
from glue import segments
from pycbc_hwinj.frame import get_frame_files
from pycbc import workflow
from pycbc.workflow.core import make_external_call, OutSegFile

##### setup

# read command line
parser = argparse.ArgumentParser(usage="pycbc_make_cal_workflow [--options]",
                                 description="Workflow generator for adjusting calibration model.")
parser.add_argument("--name", type=str, required=True,
                    help="Descriptive name of the analysis.")
workflow.add_workflow_command_line_group(parser)
args = parser.parse_args()

# setup log
logging.basicConfig(format="%(asctime)s:%(levelname)s : %(message)s",
                    level=logging.INFO,datefmt="%I:%M:%S")

# directory names
run_dir = os.path.join(os.getcwd(), args.name)
datafind_dir = os.path.join(run_dir, "datafind")
check_segdb_dir = os.path.join(run_dir, "check_segdb")
check_exc_dir = os.path.join(run_dir, "check_exc")
check_bitmask_dir = os.path.join(run_dir, "check_bitmask")
check_gracedb_dir = os.path.join(run_dir, "check_gracedb")
check_schedule_dir = os.path.join(run_dir, "check_schedule")

# change into run directory and make directories that are needed
if not os.path.exists(run_dir):
    os.makedirs(run_dir)
os.chdir(run_dir)
if not os.path.exists(check_segdb_dir):
    os.makedirs(check_segdb_dir)
    os.makedirs(check_segdb_dir + "/logs")
if not os.path.exists(check_gracedb_dir):
    os.makedirs(check_gracedb_dir)
if not os.path.exists(check_schedule_dir):
    os.makedirs(check_schedule_dir)
os.chdir(run_dir)

# setup workflow
wf = workflow.Workflow(args, args.name)

# make a dict to hold frame files for each IFO
frame_files = {}
for ifo in wf.ifos:
    frame_files[ifo] = workflow.FileList([])

# analysis time of each node
stride = 2000

##### check_exc

# create a FileList to hold output files for check_exc executable
check_exc_files = workflow.FileList([])

# loop over subsections of config file for check_exc executable
exe_name = "check_exc"
for subsection in wf.cp.get_subsections(exe_name):

    # get options from config file
    frame_type = wf.cp.get_opt_tags(exe_name, "frame-type", [subsection])
    channel_name = wf.cp.get_opt_tags(exe_name, "channel-name", [subsection])
    ifo = channel_name.split(":")[0]
    tag = channel_name.split(":")[1].replace("-", "_")

    # print statement
    logging.info("Creating %s workflow nodes for %s", exe_name, channel_name)

    # setup executable to check for excitations in channel
    check_exc_files = workflow.FileList([])
    check_exc_exe = workflow.Executable(wf.cp, exe_name, ifos=ifo, universe="local",
                                        out_dir=check_exc_dir, tags=[tag])

    # see if frame files already in workflow and if not then add them
    tmp_files = get_frame_files(wf, frame_files, ifo, frame_type)

    # loop over analysis time for each node
    for start_time in range(wf.analysis_time[0], wf.analysis_time[1], stride):

        # get frame files for this node
        end_time = start_time + stride
        if wf.analysis_time[1] < end_time:
            end_time = wf.analysis_time[1]
        node_seg = segments.segment(start_time, end_time)
        node_frame_files = [tmp_file for tmp_file in tmp_files if tmp_file.segment.intersects(node_seg)]

        # make a node in the workflow to check for excitations
        check_exc_node = check_exc_exe.create_node()
        check_exc_node.add_input_list_opt("--frame-files", node_frame_files)
        check_exc_node.add_opt("--channel-name", channel_name)
        check_exc_node.add_opt("--start-time", node_seg[0])
        check_exc_node.add_opt("--end-time", node_seg[1])
        check_exc_file = check_exc_node.new_output_file_opt(node_seg, "txt", "--output-file")
        check_exc_files.append(check_exc_file)
        wf.add_node(check_exc_node)

##### check_bitmask

# create list for holding output files
check_bitmask_files = workflow.FileList([])

# loop over subsections of config file for check_exc executable
exe_name = "check_bitmask"
for subsection in wf.cp.get_subsections(exe_name):

    # get options from config file
    frame_type = wf.cp.get_opt_tags(exe_name, "frame-type", [subsection])
    channel_name = wf.cp.get_opt_tags(exe_name, "channel-name", [subsection])
    bitmask_name = wf.cp.get_opt_tags(exe_name, "bitmask-name", [subsection])
    bitmask = wf.cp.get_opt_tags(exe_name, "bitmask", [subsection])
    ifo = channel_name.split(":")[0]

    # print statement
    logging.info("Creating %s workflow nodes for %s %s", exe_name, channel_name, bitmask_name)

    # setup executable to check for ODC bit transitions in channel
    check_bitmask_exe = workflow.Executable(wf.cp, exe_name, ifos=ifo, universe="local",
                                        out_dir=check_bitmask_dir, tags=[bitmask_name])

    # see if frame files already in workflow and if not then add them
    tmp_files = get_frame_files(wf, frame_files, ifo, frame_type)

    # loop over analysis time for each node
    for start_time in range(wf.analysis_time[0], wf.analysis_time[1], stride):

        # get frame files for this node
        end_time = start_time + stride
        if wf.analysis_time[1] < end_time:
            end_time = wf.analysis_time[1]
        node_seg = segments.segment(start_time, end_time)
        node_frame_files = [tmp_file for tmp_file in tmp_files if tmp_file.segment.intersects(node_seg)]

        # make a node in the workflow to check for excitations
        check_bitmask_node = check_bitmask_exe.create_node()
        check_bitmask_node.add_input_list_opt("--frame-files", node_frame_files)
        check_bitmask_node.add_opt("--channel-name", channel_name)
        check_bitmask_node.add_opt("--bitmask-name", bitmask_name)
        check_bitmask_node.add_opt("--bitmask", bitmask)
        check_bitmask_node.add_opt("--start-time", node_seg[0])
        check_bitmask_node.add_opt("--end-time", node_seg[1])
        check_bitmask_file = check_bitmask_node.new_output_file_opt(node_seg, "txt", "--output-file")
        check_bitmask_files.append(check_bitmask_file)
        wf.add_node(check_bitmask_node)

##### check_segdb

# make a dict to hold segment files for each IFO
segment_files = {}
for ifo in wf.ifos:
    segment_files[ifo] = workflow.FileList([])

# create list for holding output files
check_segdb_files = workflow.FileList([])

# loop over subsections of config file for check_exc executable
exe_name = "check_segdb"
for subsection in wf.cp.get_subsections(exe_name):

    # get options from config file
    database_url = wf.cp.get_opt_tags(exe_name, "database-url", [subsection])
    segment_name = wf.cp.get_opt_tags(exe_name, "segment-name", [subsection])
    ifo, segment_flag, version = segment_name.split(":")

    # print statement
    logging.info("Querying %s workflow nodes for %s", exe_name, segment_name)

    # construct output path
    output_path = os.path.join(check_segdb_dir,
        ifo + "-" + segment_flag.replace("-", "_") + "_" + version + "-" + str(wf.analysis_time[0]) + "-" + str(abs(wf.analysis_time)) + ".xml.gz")

    # construct command line for segdb external call
    cmd = [wf.cp.get("executables", exe_name),
            "--query-segments",
            "--segment-url", database_url,
            "--gps-start-time", str(wf.analysis_time[0]),
            "--gps-end-time", str(wf.analysis_time[1]),
            "--include-segments", segment_name,
            "--output-file", output_path]
  
    # make an external call to query segment database
    make_external_call(cmd, out_dir=os.path.join(check_segdb_dir,"logs"),
                            out_basename=ifo.lower() + "-" + segment_flag.lower() + "-" + version)

    # Yes its poor to generate a file and then read it back in
    # new segment database API should fix this
    seg_url  = urlparse.urlunparse(["file", "localhost", output_path,
                                   None, None, None])
    seg_file = OutSegFile(ifo, "CHECK_SEGDB",
                          wf.analysis_time, seg_url, segment_list=[],
                                  tags=[segment_flag])
    seg_file.PFN(output_path, site="local")
    segment_files[ifo].append(seg_file)

##### check_gracedb

# print statement
logging.info("Querying gracedb rest API for all triggers")

# get gracedb events
client = gracedb_rest.GraceDb()
query = str(wf.analysis_time[0]) + " .. " + str(wf.analysis_time[1])
evnts = client.events(query, orderby="gpstime", columns="graceid,gpstime,pipeline,instruments")

# write gracedb events to file
ifos = "".join(wf.ifos)
path = os.path.join(check_gracedb_dir, ifos + "-" + "GRACEDB" + "-" + str(wf.analysis_time[0]) + "-" + str(abs(wf.analysis_time)) + ".txt")
with open(path, "w") as fp:
    for evnt in evnts:
        line = ",".join(map(str, [evnt["graceid"],
                        evnt["gpstime"], evnt["pipeline"],
                        "".join(evnt["instruments"].split(",")),
        ])) + "\n"
        fp.write(line)
gracedb_file = workflow.File(ifos, "GRACEDB", wf.analysis_time, file_url="file://localhost" + path)

##### check_schedule

# get tinj schedule
schedule_path = wf.cp.get("workflow-schedule", "schedule-path")

# check if schedule exists
if os.path.exists(schedule_path):

    # print statement
    logging.info("Retrieving schedule from %s", schedule_path)

    # copy schedule to run directory
    path = os.path.join(check_schedule_dir, ifos + "-" + "SCHEDULE" + "-" + str(wf.analysis_time[0]) + "-" + str(abs(wf.analysis_time)) + ".txt")
    schedule_file = workflow.File(ifos, "SCHEDULE", wf.analysis_time, file_url="file://localhost" + path)
    shutil.copy(schedule_path, path)

##### finish

# write dax
wf.save()

# done
logging.info("Done")


